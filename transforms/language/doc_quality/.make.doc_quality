MODEL_NAME=TinyLlama-1.1B-Chat-v0.6
MODEL_DIR=models

download_model:
	@# Help: Clone the cc_net repo with the kenlm model and build the model
	@if [[ ! -d "../$(MODEL_DIR)" ]]; then \
	    pip install -U "huggingface_hub[cli]"; \
		cd ../; \
		huggingface-cli download "TinyLlama/$(MODEL_NAME)" --local-dir $(MODEL_DIR); \
	fi

clean_model:
	rm -rf ../$(MODEL_DIR)

test-image-pytest:
	# Put this 2nd so its help showss up instead of .defaults.image help
	@# Help: Test $(DOCKER_LOCAL_IMAGE) using test source inside the image. 
	$(DOCKER) run -t -v $$(dirname ${PWD})/$(MODEL_DIR):$(DOCKER_HOME_DIR)/$(MODEL_DIR) --rm $(DOCKER_LOCAL_IMAGE) pytest -s test 
