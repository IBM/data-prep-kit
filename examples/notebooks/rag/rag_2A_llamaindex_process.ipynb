{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG: Process data with llama-index\n",
    "\n",
    "References\n",
    "- https://docs.llamaindex.ai/en/stable/examples/vector_stores/MilvusIndexDemo/\n",
    "- https://docs.llamaindex.ai/en/stable/api_reference/storage/vector_store/milvus/?h=milvusvectorstore#llama_index.vector_stores.milvus.MilvusVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig:\n",
    "    pass\n",
    "\n",
    "MY_CONFIG = MyConfig()\n",
    "\n",
    "MY_CONFIG.EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "MY_CONFIG.EMBEDDING_LENGTH = 384\n",
    "\n",
    "MY_CONFIG.INPUT_DATA_DIR = \"input_data/walmart-reports-1\"\n",
    "\n",
    "MY_CONFIG.DB_URI = './rag_2_llamaindex.db'\n",
    "MY_CONFIG.COLLECTION_NAME = 'llamaindex_walmart_docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 chunks\n",
      "CPU times: user 7.95 s, sys: 1.5 s, total: 9.45 s\n",
      "Wall time: 7.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import pprint\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    # input_dir = './data/10k/input/'\n",
    "    input_dir = MY_CONFIG.INPUT_DATA_DIR\n",
    ").load_data()\n",
    "\n",
    "print (f\"Loaded {len(documents)} chunks\")\n",
    "\n",
    "# print(\"Document [0].doc_id:\", documents[0].doc_id)\n",
    "# pprint.pprint (documents[0], indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/my-stuff/projects/ai-alliance/data-prep-kit-sujee/examples/notebooks/rag/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = MY_CONFIG.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Milvus instance:  ./rag_2_llamaindex.db\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(MY_CONFIG.DB_URI)\n",
    "print (\"✅ Connected to Milvus instance: \", MY_CONFIG.DB_URI )\n",
    "\n",
    "# if we already have a collection, clear it first\n",
    "if milvus_client.has_collection(collection_name = MY_CONFIG.COLLECTION_NAME):\n",
    "    milvus_client.drop_collection(collection_name = MY_CONFIG.COLLECTION_NAME)\n",
    "    print ('✅ Cleared collection :', MY_CONFIG.COLLECTION_NAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected Llama-index to Milvus instance:  ./rag_2_llamaindex.db\n"
     ]
    }
   ],
   "source": [
    "# connect to vector db\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri = MY_CONFIG.DB_URI ,\n",
    "    dim = MY_CONFIG.EMBEDDING_LENGTH , \n",
    "    collection_name = MY_CONFIG.COLLECTION_NAME,\n",
    "    overwrite=True\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print (\"✅ Connected Llama-index to Milvus instance: \", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created index: <llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x72078bfbaf10>\n",
      "CPU times: user 4.49 s, sys: 237 ms, total: 4.73 s\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create an index\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "print (\"✅ Created index:\", index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved documents and data into collection : llamaindex_walmart_docs\n",
      "CPU times: user 5.43 ms, sys: 2.92 ms, total: 8.35 ms\n",
      "Wall time: 6.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "## Save index to disk\n",
    "index.storage_context.persist()\n",
    "print (\"✅ Saved documents and data into collection :\", MY_CONFIG.COLLECTION_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llamaindex_walmart_docs']\n",
      "---------\n",
      "{'aliases': [],\n",
      " 'auto_id': False,\n",
      " 'collection_id': 0,\n",
      " 'collection_name': 'llamaindex_walmart_docs',\n",
      " 'consistency_level': 0,\n",
      " 'description': '',\n",
      " 'enable_dynamic_field': True,\n",
      " 'fields': [{'description': '',\n",
      "             'field_id': 100,\n",
      "             'is_primary': True,\n",
      "             'name': 'id',\n",
      "             'params': {'max_length': 65535},\n",
      "             'type': <DataType.VARCHAR: 21>},\n",
      "            {'description': '',\n",
      "             'field_id': 101,\n",
      "             'name': 'embedding',\n",
      "             'params': {'dim': 384},\n",
      "             'type': <DataType.FLOAT_VECTOR: 101>}],\n",
      " 'num_partitions': 0,\n",
      " 'num_shards': 0,\n",
      " 'properties': {}}\n"
     ]
    }
   ],
   "source": [
    "# See data in vector db\n",
    "\n",
    "from pymilvus import MilvusClient\n",
    "import pprint \n",
    "\n",
    "milvus_client = MilvusClient(MY_CONFIG.DB_URI)\n",
    "res = milvus_client.list_collections()\n",
    "\n",
    "print(res)\n",
    "print ('---------')\n",
    "\n",
    "res = milvus_client.describe_collection(\n",
    "    collection_name = MY_CONFIG.COLLECTION_NAME\n",
    ")\n",
    "\n",
    "pprint.pprint(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
