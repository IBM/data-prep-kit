{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e533d-ebb3-406d-9da7-b19e2c5f5866",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #04D7FD; padding: 20px; text-align: left;\">\n",
    "    <h1 style=\"color: #000000; font-size: 36px; margin: 0;\">Data Processing for RAG with Data Prep Kit</h1>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15976e3",
   "metadata": {},
   "source": [
    "## Before Running the notebook\n",
    "\n",
    "Please complete [setting up python dev environment](./setup-python-dev-env.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ecf08-5f62-4b99-9347-8a0955843d21",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will process PDF documents as part of RAG pipeline\n",
    "\n",
    "![](media/rag-overview-2.png)\n",
    "\n",
    "This notebook will perform steps 1, 2 and 3 in RAG pipeline.\n",
    "\n",
    "Here are the processing steps:\n",
    "\n",
    "- **pdf2parquet** : Extract text from PDF and convert them into parquet files\n",
    "- **Chunk documents**: Split the PDFs into 'meaningful sections' (paragraphs, sentences ..etc)\n",
    "- **Exact Dedup**: Chunks with exact same content are filtered out\n",
    "- **Doc_ID generation**: Each chunk is assigned a uniq id, based on content and hash\n",
    "- **Fuzzy Dedup**: Eliminate chunks that are 'very similar' content\n",
    "- **Doc quality**: Scores the documents based on criteria like number of words, if it contains bad words ..etc\n",
    "- **Text encoder**: Convert chunks into vectors using embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b10be1",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33345487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "## Configuration\n",
    "class MyConfig:\n",
    "    pass \n",
    "\n",
    "MY_CONFIG = MyConfig ()\n",
    "\n",
    "## Input Data - configure this to the folder we want to process\n",
    "MY_CONFIG.INPUT_DATA_DIR = \"input\"\n",
    "MY_CONFIG.OUTPUT_FOLDER = \"output\"\n",
    "MY_CONFIG.OUTPUT_FOLDER_FINAL = os.path.join(MY_CONFIG.OUTPUT_FOLDER , \"output_final\")\n",
    "\n",
    "## Embedding model\n",
    "MY_CONFIG.EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "## RAY CONFIGURATION\n",
    "num_cpus_available =  os.cpu_count()\n",
    "# print (num_cpus_available)\n",
    "# MY_CONFIG.RAY_NUM_CPUS = num_cpus_available // 2  ## use half the available cores for processing\n",
    "MY_CONFIG.RAY_NUM_CPUS =  1\n",
    "# print (MY_CONFIG.RAY_NUM_CPUS)\n",
    "MY_CONFIG.RAY_MEMORY_GB = 2  # GB\n",
    "# MY_CONFIG.RAY_RUNTIME_WORKERS = num_cpus_available // 3\n",
    "MY_CONFIG.RAY_RUNTIME_WORKERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc3f0e",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "We will use [Walmart annual report PDFs](https://github.com/sujee/data/tree/main/data-prep-kit/walmart-reports-1) as our input data.\n",
    "\n",
    "Feel free to substitute your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c1ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file 'input/Walmart-10K-Reports-Optimized_2023.pdf' (1.61 MB) already exists. Skipping download.\n",
      "Local file 'input/Walmart_2024.pdf' (4.87 MB) already exists. Skipping download.\n",
      "Local file 'input/Walmart_2024_copy.pdf' (4.87 MB) already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "from utils import download_file\n",
    "\n",
    "## Download the data files\n",
    "shutil.os.makedirs(MY_CONFIG.INPUT_DATA_DIR, exist_ok=True)\n",
    "\n",
    "download_file (url = 'https://raw.githubusercontent.com/sujee/data/main/data-prep-kit/walmart-reports-1/Walmart-10K-Reports-Optimized_2023.pdf', local_file = os.path.join(MY_CONFIG.INPUT_DATA_DIR, 'Walmart-10K-Reports-Optimized_2023.pdf' ))\n",
    "\n",
    "download_file (url = 'https://raw.githubusercontent.com/sujee/data/main/data-prep-kit/walmart-reports-1/Walmart_2024.pdf', local_file = os.path.join(MY_CONFIG.INPUT_DATA_DIR, 'Walmart_2024.pdf' ))\n",
    "\n",
    "download_file (url = 'https://raw.githubusercontent.com/sujee/data/main/data-prep-kit/walmart-reports-1/Walmart_2024.pdf', local_file = os.path.join(MY_CONFIG.INPUT_DATA_DIR, 'Walmart_2024_copy.pdf' ))  # create a dupe file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72510ae6-48b0-4b88-9e13-a623281c3a63",
   "metadata": {},
   "source": [
    "### Set input/output path variables for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ac8bee-0960-4309-b225-d7a211b14262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleared output directory\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists(MY_CONFIG.INPUT_DATA_DIR ):\n",
    "    raise Exception (f\"‚ùå Input folder MY_CONFIG.INPUT_DATA_DIR = '{MY_CONFIG.INPUT_DATA_DIR}' not found\")\n",
    "\n",
    "\n",
    "## clear output folder\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_FOLDER, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print (\"‚úÖ Cleared output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d976e-cb4c-4469-af39-4b7ea507e9d8",
   "metadata": {},
   "source": [
    "### Import Common python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66178913-42b8-426b-a2e9-9587268fd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Main repo root\n",
    "from utils import rootdir\n",
    "\n",
    "from data_processing_ray.runtime.ray import RayTransformLauncher\n",
    "from data_processing.runtime.pure_python import PythonTransformLauncher\n",
    "from data_processing.utils import ParamsUtils\n",
    "\n",
    "STAGE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449e5c7-078c-4ad6-a2f6-21d39d4da3fb",
   "metadata": {},
   "source": [
    "<a id=\"pdf2parquet\"></a>\n",
    "\n",
    "## Step-2: pdf2parquet -  Convert data from PDF to Parquet\n",
    "\n",
    "This step is reading the input folder containing all PDF files and ingest them in a parquet table using the [Docling package](https://github.com/DS4SD/docling).\n",
    "The documents are converted into a JSON format which allows to easily chunk it in the later steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c574c4-9dc4-4dab-9ad6-b5338207e67a",
   "metadata": {},
   "source": [
    "### Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482605b2-d814-456d-9195-49a2ec454ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-1: Processing input='input' --> output='output/01_parquet_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE  += 1\n",
    "# STAGE = 1  ## DEBUG\n",
    "\n",
    "input_folder = MY_CONFIG.INPUT_DATA_DIR\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_parquet_out\")\n",
    "\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb15f02-ab5c-4525-a536-cfa1fd2ba70b",
   "metadata": {},
   "source": [
    "### Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cd8ebd-bf71-42d6-a397-8df0c7b66a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:27:06 INFO - Running locally\n",
      "10:27:06 INFO - pdf2parquet parameters are : {'artifacts_path': None, 'contents_type': <pdf2parquet_contents_types.JSON: 'application/json'>, 'do_table_structure': True, 'do_ocr': False}\n",
      "10:27:06 INFO - data factory data_ is using local data access: input_folder - input output_folder - output/01_parquet_out\n",
      "10:27:06 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:27:06 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.pdf'], files to checkpoint ['.parquet']\n",
      "10:27:06 INFO - pipeline id pipeline_id\n",
      "10:27:06 INFO - code location {'github': 'github', 'commit_hash': '12345', 'path': 'path'}\n",
      "10:27:06 INFO - number of workers 2 worker options {'num_cpus': 1, 'memory': 2147483648, 'max_restarts': -1}\n",
      "10:27:06 INFO - actor creation delay 0\n",
      "10:27:06 INFO - job details {'job category': 'preprocessing', 'job name': 'pdf2parquet', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:27:08,526\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:27:13 INFO - orchestrator started at 2024-08-30 10:27:13\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:27:13 INFO - Number of files is 3, source profile {'max_file_size': 4.640201568603516, 'min_file_size': 1.5370569229125977, 'total_file_size': 10.817460060119629}\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:27:13 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.336485291831195, 'object_store': 4.168242644518614}\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:27:13 INFO - Number of workers - 2 with {'num_cpus': 1, 'memory': 2147483648, 'max_restarts': -1} each\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 10:27:17 INFO - Initializing models\n",
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 30615.36it/s]\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m /home/sujee/apps/anaconda3/envs/data-prep-kit-3-py311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:29.093 ( 315.179s) [        48BC0740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-unselected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 10:27:17 INFO - Initializing models\n",
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 97867.09it/s]\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m /home/sujee/apps/anaconda3/envs/data-prep-kit-3-py311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:31.255 ( 317.341s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1011\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:31.764 ( 317.850s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1037\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:31.833 ( 317.919s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1176\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:32.154 ( 318.240s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1321\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:32:32.543 ( 318.629s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1103\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:32:40 INFO - Completed 1 files in 5.459707876046498 min\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:32:40 INFO - Completed 1 files (33.333333333333336%)  in 5.459709358215332 min. Waiting for completion\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 2024-08-30 10:32:45.826 ( 331.904s) [        54E47740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-unselected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 2024-08-30 10:32:45.826 ( 331.904s) [        54E47740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-selected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 2024-08-30 10:32:45.826 ( 331.904s) [        54E47740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-unselected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 2024-08-30 10:32:45.826 ( 331.904s) [        54E47740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-unselected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074217)\u001b[0m 2024-08-30 10:32:45.826 ( 331.904s) [        54E47740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-selected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:29.521 ( 615.607s) [        48BC0740]    doc_normalisation.h:448   WARN| found new `other` type: checkbox-unselected\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:31.651 ( 617.737s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1011\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:32.128 ( 618.214s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1037\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:32.195 ( 618.281s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1176\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:32.511 ( 618.597s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1321\n",
      "\u001b[36m(RayTransformFileProcessor pid=1074216)\u001b[0m 2024-08-30 10:37:32.873 ( 618.959s) [        48BC0740]          crf_model.cpp:2096   ERR| sequence is too long: 1000 > 1103\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:37:40 INFO - Completed processing 3 files in 10.459254721800486 min\n",
      "\u001b[36m(orchestrate pid=1073282)\u001b[0m 10:37:40 INFO - done flushing in 0.0009496212005615234 sec\n",
      "10:37:50 INFO - Completed execution in 10.735311404863994 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:1 completed successfully\n",
      "CPU times: user 4.08 s, sys: 1.07 s, total: 5.15 s\n",
      "Wall time: 10min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pdf2parquet_transform import (\n",
    "    pdf2parquet_contents_type_cli_param,\n",
    "    pdf2parquet_contents_types,\n",
    ")\n",
    "from pdf2parquet_transform_python import Pdf2ParquetPythonTransformConfiguration\n",
    "from pdf2parquet_transform_ray import Pdf2ParquetRayTransformConfiguration\n",
    "\n",
    "from data_processing.utils import GB, ParamsUtils\n",
    "\n",
    "\n",
    "# create parameters\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS, \"memory\": MY_CONFIG.RAY_MEMORY_GB * GB}\n",
    "code_location = {\"github\": \"github\", \"commit_hash\": \"12345\", \"path\": \"path\"}\n",
    "ingest_config = {\n",
    "    pdf2parquet_contents_type_cli_param: pdf2parquet_contents_types.JSON,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    \"data_files_to_use\": ast.literal_eval(\"['.pdf']\"),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    \"runtime_pipeline_id\": \"pipeline_id\",\n",
    "    \"runtime_job_id\": \"job_id\",\n",
    "    \"runtime_code_location\": ParamsUtils.convert_to_ast(code_location),\n",
    "}\n",
    "\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=(params | ingest_config))\n",
    "# create launcher\n",
    "launcher = RayTransformLauncher(Pdf2ParquetRayTransformConfiguration())\n",
    "# launcher = PythonTransformLauncher(Pdf2ParquetPythonTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca790e0",
   "metadata": {},
   "source": [
    "### Inspect Generated output\n",
    "\n",
    "Here we should see one entry per input file processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe59563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions (rows x columns)=  (3, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>{\"_name\":\"\",\"type\":\"pdf-document\",\"description...</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "      <td>{\"_name\":\"\",\"type\":\"pdf-document\",\"description...</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>95cc2911-9a0d-49c3-a259-c74e35fca3ea</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...</td>\n",
       "      <td>1112050</td>\n",
       "      <td>2024-08-30T10:37:40.616022</td>\n",
       "      <td>299.935132</td>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>{\"_name\":\"\",\"type\":\"pdf-document\",\"description...</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  \\\n",
       "0  Walmart-10K-Reports-Optimized_2023.pdf   \n",
       "1                   Walmart_2024_copy.pdf   \n",
       "2                        Walmart_2024.pdf   \n",
       "\n",
       "                                            contents  num_pages  num_tables  \\\n",
       "0  {\"_name\":\"\",\"type\":\"pdf-document\",\"description...        100          81   \n",
       "1  {\"_name\":\"\",\"type\":\"pdf-document\",\"description...        100          82   \n",
       "2  {\"_name\":\"\",\"type\":\"pdf-document\",\"description...        100          82   \n",
       "\n",
       "   num_doc_elements                           document_id  ext  \\\n",
       "0              1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "1              1163  95cc2911-9a0d-49c3-a259-c74e35fca3ea  pdf   \n",
       "2              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "\n",
       "                                                hash     size  \\\n",
       "0  ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "1  0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...  1112050   \n",
       "2  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "\n",
       "                date_acquired  pdf_convert_time  \\\n",
       "0  2024-08-30T10:32:49.798524        321.107279   \n",
       "1  2024-08-30T10:37:40.616022        299.935132   \n",
       "2  2024-08-30T10:32:40.640835        312.142404   \n",
       "\n",
       "                          source_filename  \n",
       "0  Walmart-10K-Reports-Optimized_2023.pdf  \n",
       "1                   Walmart_2024_copy.pdf  \n",
       "2                        Walmart_2024.pdf  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(5)\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72274586",
   "metadata": {},
   "source": [
    "<a id=\"chunking\"></a>\n",
    "\n",
    "##  Step-3: Doc chunks\n",
    "\n",
    "Split the documents in chunks, according to their layout segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96198fa6",
   "metadata": {},
   "source": [
    "### Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305f00a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-2: Processing input='output/01_parquet_out' --> output='output/02_chunk_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE  += 1\n",
    "# STAGE = 2  ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_chunk_out\")\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f2cd1",
   "metadata": {},
   "source": [
    "### Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7b18d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/sujee/apps/anaconda3/envs/data-prep-\n",
      "[nltk_data]     kit-3-py311/lib/python3.11/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "10:37:53 INFO - Running locally\n",
      "10:37:53 INFO - doc_chunk parameters are : {'chunking_type': <chunking_types.DL_JSON: 'dl_json'>, 'content_column_name': 'contents', 'output_chunk_column_name': 'contents', 'output_jsonpath_column_name': 'doc_jsonpath', 'output_pageno_column_name': 'page_number', 'output_bbox_column_name': 'bbox'}\n",
      "10:37:53 INFO - data factory data_ is using local data access: input_folder - output/01_parquet_out output_folder - output/02_chunk_out\n",
      "10:37:53 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:37:53 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:37:53 INFO - pipeline id pipeline_id\n",
      "10:37:53 INFO - code location None\n",
      "10:37:53 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:37:53 INFO - actor creation delay 0\n",
      "10:37:53 INFO - job details {'job category': 'preprocessing', 'job name': 'doc_chunk', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:37:55,040\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m [nltk_data] Downloading package punkt_tab to\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m [nltk_data]     /home/sujee/apps/anaconda3/envs/data-prep-\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m [nltk_data]     kit-3-py311/lib/python3.11/site-\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m [nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m [nltk_data]   Package punkt_tab is already up-to-date!\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:57 INFO - orchestrator started at 2024-08-30 10:37:57\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:57 INFO - Number of files is 3, source profile {'max_file_size': 0.3565502166748047, 'min_file_size': 0.35198307037353516, 'total_file_size': 1.060612678527832}\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:57 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.289907838217914, 'object_store': 4.144953917711973}\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:57 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:59 INFO - Completed 1 files in 0.03202696243921916 min\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:59 INFO - Completed 1 files (33.333333333333336%)  in 0.032028536001841225 min. Waiting for completion\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:59 INFO - Completed processing 3 files in 0.03510438601175944 min\n",
      "\u001b[36m(orchestrate pid=1088698)\u001b[0m 10:37:59 INFO - done flushing in 0.0009315013885498047 sec\n",
      "10:38:09 INFO - Completed execution in 0.26731717586517334 min, execution result 0\n",
      "\u001b[36m(RayTransformFileProcessor pid=1089568)\u001b[0m [nltk_data] Downloading package punkt_tab to\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTransformFileProcessor pid=1089568)\u001b[0m [nltk_data]     kit-3-py311/lib/python3.11/site-\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTransformFileProcessor pid=1089568)\u001b[0m [nltk_data]     packages/llama_index/core/_static/nltk_cache...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTransformFileProcessor pid=1089567)\u001b[0m [nltk_data]   Package punkt_tab is already up-to-date!\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:2 completed successfully\n",
      "CPU times: user 1.35 s, sys: 997 ms, total: 2.35 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Import doc_json_chunk transform configuration\n",
    "from doc_chunk_transform_ray import DocChunkRayTransformConfiguration\n",
    "\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    # doc_chunk arguments\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Pass the commandline params\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "\n",
    "# create launcher\n",
    "launcher = RayTransformLauncher(DocChunkRayTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213afdf6",
   "metadata": {},
   "source": [
    "### Inspect Generated output\n",
    "\n",
    "We would see documents are split into many chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8138d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : 3\n",
      "Chunks created : 2,042\n",
      "Input data dimensions (rows x columns)=  (3, 12)\n",
      "Output data dimensions (rows x columns)=  (2042, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>doc_jsonpath</th>\n",
       "      <th>page_number</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>95cc2911-9a0d-49c3-a259-c74e35fca3ea</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...</td>\n",
       "      <td>1112050</td>\n",
       "      <td>2024-08-30T10:37:40.616022</td>\n",
       "      <td>299.935132</td>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "      <td>#26*1.88*)  &amp;62.2,7\\n*F=CF HC H&lt;9 .5L  IHG 5B8...</td>\n",
       "      <td>$.main-text[891]</td>\n",
       "      <td>76</td>\n",
       "      <td>[35.41, 538.52, 546.86, 609.18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>67:?:E:@? 2?5 #:&gt;:E2E:@?D @7  ?E6C?2=  @?EC@=...</td>\n",
       "      <td>$.main-text[630]</td>\n",
       "      <td>55</td>\n",
       "      <td>[35.55, 222.69, 525.53, 256.91]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>95cc2911-9a0d-49c3-a259-c74e35fca3ea</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...</td>\n",
       "      <td>1112050</td>\n",
       "      <td>2024-08-30T10:37:40.616022</td>\n",
       "      <td>299.935132</td>\n",
       "      <td>Walmart_2024_copy.pdf</td>\n",
       "      <td>.6 C6=J 6IE6?D:G6=J @? :?7@C&gt;2E:@? 2?5 7:?2?4:...</td>\n",
       "      <td>$.main-text[278]</td>\n",
       "      <td>25</td>\n",
       "      <td>[35.23, 641.07, 547.64, 747.74]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  num_pages  num_tables  num_doc_elements  \\\n",
       "1229  Walmart_2024_copy.pdf        100          82              1163   \n",
       "1767       Walmart_2024.pdf        100          82              1163   \n",
       "865   Walmart_2024_copy.pdf        100          82              1163   \n",
       "\n",
       "                               document_id  ext  \\\n",
       "1229  95cc2911-9a0d-49c3-a259-c74e35fca3ea  pdf   \n",
       "1767  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "865   95cc2911-9a0d-49c3-a259-c74e35fca3ea  pdf   \n",
       "\n",
       "                                                   hash     size  \\\n",
       "1229  0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...  1112050   \n",
       "1767  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "865   0be5657667eb7229f1389625f61b6d6dfb608c617ed5ef...  1112050   \n",
       "\n",
       "                   date_acquired  pdf_convert_time        source_filename  \\\n",
       "1229  2024-08-30T10:37:40.616022        299.935132  Walmart_2024_copy.pdf   \n",
       "1767  2024-08-30T10:32:40.640835        312.142404       Walmart_2024.pdf   \n",
       "865   2024-08-30T10:37:40.616022        299.935132  Walmart_2024_copy.pdf   \n",
       "\n",
       "                                               contents      doc_jsonpath  \\\n",
       "1229  #26*1.88*)  &62.2,7\\n*F=CF HC H<9 .5L  IHG 5B8...  $.main-text[891]   \n",
       "1767   67:?:E:@? 2?5 #:>:E2E:@?D @7  ?E6C?2=  @?EC@=...  $.main-text[630]   \n",
       "865   .6 C6=J 6IE6?D:G6=J @? :?7@C>2E:@? 2?5 7:?2?4:...  $.main-text[278]   \n",
       "\n",
       "      page_number                             bbox  \n",
       "1229           76  [35.41, 538.52, 546.86, 609.18]  \n",
       "1767           55  [35.55, 222.69, 525.53, 256.91]  \n",
       "865            25  [35.23, 641.07, 547.64, 747.74]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (f\"Files processed : {input_df.shape[0]:,}\")\n",
    "print (f\"Chunks created : {output_df.shape[0]:,}\")\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692975c-49ff-41ae-810e-0f5bc0bbdc53",
   "metadata": {},
   "source": [
    "## Step-4: Exact Dedup\n",
    "\n",
    "Remove documents having identical code to remove bias in the training data. On the content of each document, a SHA256 hash is computed,\n",
    "followed by de-duplication of record having identical hashes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfd3a2-a236-4143-bcfc-15804f1da7fe",
   "metadata": {},
   "source": [
    "### Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7a1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-3: Processing input='output/02_chunk_out' --> output='output/03_ededupe_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE  += 1\n",
    "# STAGE  = 3  ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_ededupe_out\")\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661cb37-39c7-4b09-a784-925bfa9eaf1e",
   "metadata": {},
   "source": [
    "### Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a624b2b2-faad-4325-ac7d-53a840f564ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38:10 INFO - Running locally\n",
      "10:38:10 INFO - exact dedup params are {'doc_column': 'contents', 'hash_cpu': 0.5, 'num_hashes': 2}\n",
      "10:38:10 INFO - data factory data_ is using local data access: input_folder - output/02_chunk_out output_folder - output/03_ededupe_out\n",
      "10:38:10 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:38:10 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:38:10 INFO - pipeline id pipeline_id\n",
      "10:38:10 INFO - code location None\n",
      "10:38:10 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:38:10 INFO - actor creation delay 0\n",
      "10:38:10 INFO - job details {'job category': 'preprocessing', 'job name': 'ededup', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:38:12,554\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:13 INFO - orchestrator started at 2024-08-30 10:38:13\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:13 INFO - Number of files is 3, source profile {'max_file_size': 0.20615005493164062, 'min_file_size': 0.19641399383544922, 'total_file_size': 0.5990447998046875}\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:13 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.27267990168184, 'object_store': 4.136339950375259}\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:13 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:14 INFO - Completed 1 files in 0.011358428001403808 min\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:14 INFO - Completed 1 files (33.333333333333336%)  in 0.011360756556193034 min. Waiting for completion\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:14 INFO - Completed processing 3 files in 0.01162503957748413 min\n",
      "\u001b[36m(orchestrate pid=1090364)\u001b[0m 10:38:14 INFO - done flushing in 0.0009477138519287109 sec\n",
      "10:38:24 INFO - Completed execution in 0.2259385307629903 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:3 completed successfully\n",
      "CPU times: user 121 ms, sys: 184 ms, total: 305 ms\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import ededup transform configuration\n",
    "from ededup_transform_ray import EdedupRayTransformConfiguration\n",
    "\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    # ededup parameters\n",
    "    \"ededup_hash_cpu\": 0.5,\n",
    "    \"ededup_num_hashes\": 2,\n",
    "    \"ededup_doc_column\": \"contents\",\n",
    "}\n",
    "\n",
    "# Pass the commandline params\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "\n",
    "# create launcher\n",
    "launcher = RayTransformLauncher(EdedupRayTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1c3c3",
   "metadata": {},
   "source": [
    "### Inspect Generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d824ebf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (2042, 15)\n",
      "Output data dimensions (rows x columns)=  (1324, 15)\n",
      "Input chunks before exact dedupe : 2,042\n",
      "Output chunks after exact dedupe : 1,324\n",
      "Duplicate chunks removed :   718\n"
     ]
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (f\"Input chunks before exact dedupe : {input_df.shape[0]:,}\")\n",
    "print (f\"Output chunks after exact dedupe : {output_df.shape[0]:,}\")\n",
    "print (\"Duplicate chunks removed :  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f4d00-33bb-4d9a-9f34-4d7f3ee0b7bc",
   "metadata": {},
   "source": [
    "## Step-5:  DOC ID generation\n",
    "\n",
    "This transform annotates documents with document \"ids\". It supports the following transformations of the original data:\n",
    "\n",
    " - Adding document hash: this enables the addition of a document hash-based id to the data. The hash is calculated with `hashlib.sha256(doc.encode(\"utf-8\")).hexdigest()`. To enable this annotation, set hash_column to the name of the column, where you want to store it.\n",
    " - Adding integer document id: this allows the addition of an integer document id to the data that is unique across all rows in all tables provided to the transform() method. To enable this annotation, set int_id_column to the name of the column, where you want to store it. **This is a pre-requisite for fuzzy dedup** in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f62394-fbde-495c-bbbb-83161b006bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-4: Processing input='output/03_ededupe_out' --> output='output/04_doc_id_out'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input for this stage is the output of exact dedeup component\n",
    "# output of this component makes it possible for fdedup component to run on data.\n",
    "\n",
    "STAGE  += 1\n",
    "# STAGE  = 4  ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_doc_id_out\")\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6daf36d-686c-4e0a-aabf-ce55f999bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38:25 INFO - Running locally\n",
      "10:38:25 INFO - Doc id parameters are : {'doc_column': 'contents', 'hash_column': 'hash_column', 'int_column': 'int_id_column'}\n",
      "10:38:25 INFO - data factory data_ is using local data access: input_folder - output/03_ededupe_out output_folder - output/04_doc_id_out\n",
      "10:38:25 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:38:25 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:38:25 INFO - pipeline id pipeline_id\n",
      "10:38:25 INFO - code location None\n",
      "10:38:25 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:38:25 INFO - actor creation delay 0\n",
      "10:38:25 INFO - job details {'job category': 'preprocessing', 'job name': 'doc_id', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:38:27,443\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:28 INFO - orchestrator started at 2024-08-30 10:38:28\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:28 INFO - Number of files is 3, source profile {'max_file_size': 0.20574665069580078, 'min_file_size': 0.003185272216796875, 'total_file_size': 0.4063444137573242}\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:28 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.265644073486328, 'object_store': 4.132822036743164}\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:28 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:29 INFO - Completed 1 files in 0.012215912342071533 min\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:29 INFO - Completed 1 files (33.333333333333336%)  in 0.012217283248901367 min. Waiting for completion\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:29 INFO - Completed processing 3 files in 0.012248762448628743 min\n",
      "\u001b[36m(orchestrate pid=1092147)\u001b[0m 10:38:29 INFO - done flushing in 0.0009109973907470703 sec\n",
      "\u001b[36m(RayTransformFileProcessor pid=1092988)\u001b[0m 10:38:29 WARNING - table is empty, skipping processing\n",
      "10:38:39 INFO - Completed execution in 0.22525110244750976 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:4 completed successfully\n",
      "CPU times: user 136 ms, sys: 159 ms, total: 296 ms\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from doc_id_transform_ray import DocIDRayTransformConfiguration\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    # doc id configuration\n",
    "    \"doc_id_doc_column\": \"contents\",\n",
    "    \"doc_id_hash_column\": \"hash_column\",\n",
    "    \"doc_id_int_column\": \"int_id_column\",\n",
    "}\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "\n",
    "# launch\n",
    "\n",
    "launcher = RayTransformLauncher(DocIDRayTransformConfiguration())\n",
    "\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d492c2b",
   "metadata": {},
   "source": [
    "### Inspect Generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ade826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (1324, 15)\n",
      "Output data dimensions (rows x columns)=  (1324, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>doc_jsonpath</th>\n",
       "      <th>page_number</th>\n",
       "      <th>bbox</th>\n",
       "      <th>hash_column</th>\n",
       "      <th>int_id_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>#682=  +2I  )68F=2E@CJ   @&gt;A=:2?46  )6AFE2E:@?...</td>\n",
       "      <td>$.main-text[299]</td>\n",
       "      <td>27</td>\n",
       "      <td>[35.24, 725.11, 503.48, 747.51]</td>\n",
       "      <td>97e06840b409f4ca176c2d5b145e8f25c9d3d37c6510ac...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>A A message  from  our r CEO\\nFor the fiscal y...</td>\n",
       "      <td>$.main-text[14]</td>\n",
       "      <td>3</td>\n",
       "      <td>[214.16, 607.24, 390.6, 617.44]</td>\n",
       "      <td>2f26fa255117cd004e3fc8e4348d39fd265e570edfdbc7...</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>ITEM 15. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...</td>\n",
       "      <td>$.main-text[978]</td>\n",
       "      <td>85</td>\n",
       "      <td>[111.85, 578.01, 263.73, 587.0]</td>\n",
       "      <td>43503987ec97f0b553f02f3572b2326006b641745b7c2f...</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  num_pages  num_tables  \\\n",
       "860                        Walmart_2024.pdf        100          82   \n",
       "2    Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "607  Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "\n",
       "     num_doc_elements                           document_id  ext  \\\n",
       "860              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "2                1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "607              1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "\n",
       "                                                  hash     size  \\\n",
       "860  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "2    ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "607  ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "\n",
       "                  date_acquired  pdf_convert_time  \\\n",
       "860  2024-08-30T10:32:40.640835        312.142404   \n",
       "2    2024-08-30T10:32:49.798524        321.107279   \n",
       "607  2024-08-30T10:32:49.798524        321.107279   \n",
       "\n",
       "                            source_filename  \\\n",
       "860                        Walmart_2024.pdf   \n",
       "2    Walmart-10K-Reports-Optimized_2023.pdf   \n",
       "607  Walmart-10K-Reports-Optimized_2023.pdf   \n",
       "\n",
       "                                              contents      doc_jsonpath  \\\n",
       "860  #682=  +2I  )68F=2E@CJ   @>A=:2?46  )6AFE2E:@?...  $.main-text[299]   \n",
       "2    A A message  from  our r CEO\\nFor the fiscal y...   $.main-text[14]   \n",
       "607  ITEM 15. EXHIBITS, FINANCIAL STATEMENT SCHEDUL...  $.main-text[978]   \n",
       "\n",
       "     page_number                             bbox  \\\n",
       "860           27  [35.24, 725.11, 503.48, 747.51]   \n",
       "2              3  [214.16, 607.24, 390.6, 617.44]   \n",
       "607           85  [111.85, 578.01, 263.73, 587.0]   \n",
       "\n",
       "                                           hash_column  int_id_column  \n",
       "860  97e06840b409f4ca176c2d5b145e8f25c9d3d37c6510ac...            187  \n",
       "2    2f26fa255117cd004e3fc8e4348d39fd265e570edfdbc7...            653  \n",
       "607  43503987ec97f0b553f02f3572b2326006b641745b7c2f...           1258  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85309751-8556-41c6-ac32-84acc941bc8d",
   "metadata": {},
   "source": [
    "## Step-6: Fuzzy Dedup\n",
    "\n",
    "Post exact deduplication, fuzzy deduplication is applied with\n",
    "the goal of removing code files that may have slight variations and thereby unbiasing\n",
    "the data further. Small variations are quite commonly seen in code data in the form\n",
    "of variations in the values of variables, addittion of logging statements etc. Find near-\n",
    "duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf574a3-b287-419c-9c86-07b828b41ca6",
   "metadata": {},
   "source": [
    "### Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e431c8c-c7c7-48de-ba5f-2c4649c35399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-5: Processing input='output/04_doc_id_out' --> output='output/05_fdedupe_out'\n"
     ]
    }
   ],
   "source": [
    "## Input to this component is the output of doc_id generator component. \n",
    "\n",
    "STAGE  += 1\n",
    "# STAGE  = 5  ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_fdedupe_out\")\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c82a8f-b513-4fe5-b172-d41b104b54f3",
   "metadata": {},
   "source": [
    "### Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3864ff77-e9a8-48f7-973b-c3b3aef1a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38:40 INFO - Running locally\n",
      "10:38:40 INFO - fuzzy dedup params are {'doc_column': 'contents', 'id_column': 'int_id_column', 'cluster_column': 'hash_column', 'bucket_cpu': 0.5, 'mhash_cpu': 0.5, 'doc_cpu': 0.5, 'num_doc_actors': 2, 'num_minhash_actors': 1, 'num_bucket_actors': 1, 'num_preprocessors': 2, 'num_permutations': 64, 'threshold': 0.8, 'shingles_size': 5, 'delimiters': ' ', 'snapshot_delay': 1, 'use_bucket_snapshot': False, 'use_doc_snapshot': False, 'random_delay_limit': 10, 'worker_options': {'num_cpus': 1}}\n",
      "10:38:40 INFO - data factory data_ is using local data access: input_folder - output/04_doc_id_out output_folder - output/05_fdedupe_out\n",
      "10:38:40 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:38:40 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:38:40 INFO - pipeline id pipeline_id\n",
      "10:38:40 INFO - code location None\n",
      "10:38:40 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:38:40 INFO - actor creation delay 0\n",
      "10:38:40 INFO - job details {'job category': 'preprocessing', 'job name': 'fdedup', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:38:42,441\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - orchestrator started at 2024-08-30 10:38:43\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Number of files is 2, source profile {'max_file_size': 0.25233936309814453, 'min_file_size': 0.2446727752685547, 'total_file_size': 0.4970121383666992}\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.28145294263959, 'object_store': 4.140726470388472}\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - starting run from the beginning\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - continuing from the very beginning\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Fuzzy: num buckets 5, bucket length 11\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - created 1 bucket actors\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - created 1 minhash actors\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Table preprocessing uses 2 readers\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - created 2 table processor actors\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:43 INFO - Completed 0 files (0.0%)  in 6.504853566487631e-06 min. Waiting for completion\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:52 INFO - Completed processing 2 files in 0.15140592257181804 min\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:52 INFO - creating minhash snapshots\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:53 INFO - minhash snapshots created\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:53 INFO - creating bucket snapshots\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:54 INFO - bucket snapshots created\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:54 INFO - created 2 document actors\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:54 INFO - created 2 bucket processor actors\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:54 INFO - created bucket processor invoker\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:54 INFO - added invoker to bucket collectors\n",
      "\u001b[36m(BucketsHash pid=1094647)\u001b[0m 10:38:54 INFO - processing buckets 0 long, 6569 short\n",
      "\u001b[36m(BucketsHash pid=1094647)\u001b[0m 10:38:54 INFO - Done submitting long buckets\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:55 INFO - Done processing buckets in 0.011683110396067302 min\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:55 INFO - creating document snapshots\n",
      "\u001b[36m(BucketsHashProcessorInvoker pid=1095253)\u001b[0m 10:38:55 INFO - Waiting bucket processing completion. Submitted requests 66\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:57 INFO - document snapshots created\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:38:57 INFO - Completed 0 files (0.0%)  in 1.0371208190917969e-05 min. Waiting for completion\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:39:06 INFO - Completed processing 2 files in 0.1462758183479309 min\n",
      "\u001b[36m(orchestrate pid=1093805)\u001b[0m 10:39:06 INFO - done flushing in 0.001108407974243164 sec\n",
      "10:39:16 INFO - Completed execution in 0.5921090364456176 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:5 completed successfully\n",
      "CPU times: user 208 ms, sys: 195 ms, total: 402 ms\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from data_processing.utils import ParamsUtils\n",
    "from fdedup_transform_ray import FdedupRayTransformConfiguration\n",
    "\n",
    "# create parameters\n",
    "\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "code_location = {\"github\": \"github\", \"commit_hash\": \"12345\", \"path\": \"path\"}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # Orchestration parameters\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    # columns used\n",
    "    \"fdedup_doc_column\": \"contents\",\n",
    "    \"fdedup_id_column\": \"int_id_column\",\n",
    "    \"fdedup_cluster_column\": \"hash_column\",\n",
    "    # infrastructure\n",
    "    \"fdedup_bucket_cpu\": 0.5,\n",
    "    \"fdedup_doc_cpu\": 0.5,\n",
    "    \"fdedup_mhash_cpu\": 0.5,\n",
    "    \"fdedup_num_doc_actors\": 2,\n",
    "    \"fdedup_num_bucket_actors\": 1,\n",
    "    \"fdedup_num_minhash_actors\": 1,\n",
    "    \"fdedup_num_preprocessors\": 2,\n",
    "    # fuzzy parameters\n",
    "    \"fdedup_num_permutations\": 64,\n",
    "    \"fdedup_threshold\": 0.8,\n",
    "    \"fdedup_shingles_size\": 5,\n",
    "    \"fdedup_delimiters\": \" \"\n",
    "}\n",
    "\n",
    "# Pass commandline params\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "\n",
    "# launch\n",
    "\n",
    "launcher = RayTransformLauncher(FdedupRayTransformConfiguration())\n",
    "\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8cd11",
   "metadata": {},
   "source": [
    "### Inspect Generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e899ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (1324, 15)\n",
      "Output data dimensions (rows x columns)=  (1302, 17)\n",
      "Duplicate chunks removed  by fuzzy-dedupe:   22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>doc_jsonpath</th>\n",
       "      <th>page_number</th>\n",
       "      <th>bbox</th>\n",
       "      <th>int_id_column</th>\n",
       "      <th>hash_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>&amp;  %   (' ('-+(%%#'!  '- + ,-\\n(CB7CBHFC@...</td>\n",
       "      <td>$.main-text[734]</td>\n",
       "      <td>66</td>\n",
       "      <td>[35.27, 647.11, 551.24, 729.93]</td>\n",
       "      <td>447</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>Share-Based Compensation\\nFair value of restri...</td>\n",
       "      <td>$.tables[39]</td>\n",
       "      <td>68</td>\n",
       "      <td>[47.21, 61.57, 540.3, 152.39]</td>\n",
       "      <td>1123</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>Capital Resources\\nWe  believe our cash flows ...</td>\n",
       "      <td>$.main-text[517]</td>\n",
       "      <td>48</td>\n",
       "      <td>[46.39, 510.11, 539.0, 555.63]</td>\n",
       "      <td>992</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename  num_pages  num_tables  \\\n",
       "1102                        Walmart_2024.pdf        100          82   \n",
       "470   Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "339   Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "\n",
       "      num_doc_elements                           document_id  ext  \\\n",
       "1102              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "470               1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "339               1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "\n",
       "                                                   hash     size  \\\n",
       "1102  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "470   ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "339   ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "\n",
       "                   date_acquired  pdf_convert_time  \\\n",
       "1102  2024-08-30T10:32:40.640835        312.142404   \n",
       "470   2024-08-30T10:32:49.798524        321.107279   \n",
       "339   2024-08-30T10:32:49.798524        321.107279   \n",
       "\n",
       "                             source_filename  \\\n",
       "1102                        Walmart_2024.pdf   \n",
       "470   Walmart-10K-Reports-Optimized_2023.pdf   \n",
       "339   Walmart-10K-Reports-Optimized_2023.pdf   \n",
       "\n",
       "                                               contents      doc_jsonpath  \\\n",
       "1102       &  %   (' ('-+(%%#'!  '- + ,-\\n(CB7CBHFC@...  $.main-text[734]   \n",
       "470   Share-Based Compensation\\nFair value of restri...      $.tables[39]   \n",
       "339   Capital Resources\\nWe  believe our cash flows ...  $.main-text[517]   \n",
       "\n",
       "      page_number                             bbox  int_id_column  hash_column  \n",
       "1102           66  [35.27, 647.11, 551.24, 729.93]            447           -1  \n",
       "470            68    [47.21, 61.57, 540.3, 152.39]           1123           -1  \n",
       "339            48   [46.39, 510.11, 539.0, 555.63]            992           -1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (\"Duplicate chunks removed  by fuzzy-dedupe:  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646cbb7-3046-44c0-827d-d102d3ff7cb8",
   "metadata": {},
   "source": [
    "## Step-7: Document Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e985668-848b-4633-b0d8-9fe70ada0c91",
   "metadata": {},
   "source": [
    "### Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f080011-c9fe-430e-9ecc-f2220d2c8d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-6: Processing input='output/05_fdedupe_out' --> output='output/06_doc_quality_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE  += 1\n",
    "# STAGE  = 6 ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_doc_quality_out\")\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02982c5-f398-4a1a-a9fe-42d7ae748c7c",
   "metadata": {},
   "source": [
    "### Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29319fb9-b0d8-4f86-9bc5-b92960ad8ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:39:17 INFO - Running locally\n",
      "10:39:17 INFO - doc_quality parameters are : {'text_lang': 'en', 'doc_content_column': 'contents', 'bad_word_filepath': '/home/sujee/my-stuff/projects/ai-alliance/data-prep-kit-sujee/transforms/language/doc_quality/python/ldnoobw/en', 's3_cred': None, 'docq_data_factory': <data_processing.data_access.data_access_factory.DataAccessFactory object at 0x79b73a1f9210>}\n",
      "10:39:17 INFO - data factory docq_ is using local configuration without input/output path\n",
      "10:39:17 INFO - data factory docq_ max_files -1, n_sample -1\n",
      "10:39:17 INFO - data factory docq_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:39:17 INFO - data factory data_ is using local data access: input_folder - output/05_fdedupe_out output_folder - output/06_doc_quality_out\n",
      "10:39:17 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:39:17 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:39:17 INFO - pipeline id pipeline_id\n",
      "10:39:17 INFO - code location None\n",
      "10:39:17 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:39:17 INFO - actor creation delay 0\n",
      "10:39:17 INFO - job details {'job category': 'preprocessing', 'job name': 'docq', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:39:19,513\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:20 INFO - orchestrator started at 2024-08-30 10:39:20\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:20 INFO - Number of files is 2, source profile {'max_file_size': 0.20880889892578125, 'min_file_size': 0.200042724609375, 'total_file_size': 0.40885162353515625}\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:20 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.259551240131259, 'object_store': 4.129775619134307}\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:20 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:20 INFO - Completed 0 files (0.0%)  in 6.075700124104818e-06 min. Waiting for completion\n",
      "\u001b[36m(RayTransformFileProcessor pid=1097239)\u001b[0m 10:39:20 INFO - Load badwords found locally from /home/sujee/my-stuff/projects/ai-alliance/data-prep-kit-sujee/transforms/language/doc_quality/python/ldnoobw/en\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:21 INFO - Completed processing 2 files in 0.02414883772532145 min\n",
      "\u001b[36m(orchestrate pid=1096394)\u001b[0m 10:39:21 INFO - done flushing in 0.0010554790496826172 sec\n",
      "10:39:31 INFO - Completed execution in 0.23775473435719807 min, execution result 0\n",
      "\u001b[36m(RayTransformFileProcessor pid=1097238)\u001b[0m 10:39:20 INFO - Load badwords found locally from /home/sujee/my-stuff/projects/ai-alliance/data-prep-kit-sujee/transforms/language/doc_quality/python/ldnoobw/en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:6 completed successfully\n",
      "CPU times: user 139 ms, sys: 177 ms, total: 316 ms\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from doc_quality_transform import (\n",
    "    text_lang_cli_param,\n",
    "    doc_content_column_cli_param,\n",
    "    bad_word_filepath_cli_param,\n",
    ")\n",
    "from doc_quality_transform_ray import DocQualityRayTransformConfiguration\n",
    "from data_processing.utils import ParamsUtils\n",
    "\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "doc_quality_basedir = os.path.join(rootdir, \"transforms\", \"language\", \"doc_quality\", \"python\")\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    \"runtime_pipeline_id\": \"pipeline_id\",\n",
    "    \"runtime_job_id\": \"job_id\",\n",
    "    \"runtime_creation_delay\": 0,\n",
    "    # doc quality configuration\n",
    "    text_lang_cli_param: \"en\",\n",
    "    doc_content_column_cli_param: \"contents\",\n",
    "    bad_word_filepath_cli_param: os.path.join(doc_quality_basedir, \"ldnoobw\", \"en\"),\n",
    "}\n",
    "\n",
    "\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "\n",
    "# create launcher\n",
    "launcher = RayTransformLauncher(DocQualityRayTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b7d855",
   "metadata": {},
   "source": [
    "### Inspect Generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f631d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (1324, 15)\n",
      "Output data dimensions (rows x columns)=  (1302, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_mean_word_len</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>...</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>...</td>\n",
       "      <td>5.121622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>...</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename  num_pages  num_tables  \\\n",
       "354   Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "1125                        Walmart_2024.pdf        100          82   \n",
       "204   Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "\n",
       "      num_doc_elements                           document_id  ext  \\\n",
       "354               1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "1125              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "204               1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "\n",
       "                                                   hash     size  \\\n",
       "354   ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "1125  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "204   ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "\n",
       "                   date_acquired  pdf_convert_time  ... docq_mean_word_len  \\\n",
       "354   2024-08-30T10:32:49.798524        321.107279  ...           6.272727   \n",
       "1125  2024-08-30T10:32:40.640835        312.142404  ...           5.121622   \n",
       "204   2024-08-30T10:32:49.798524        321.107279  ...           5.880000   \n",
       "\n",
       "     docq_symbol_to_word_ratio docq_sentence_count  docq_lorem_ipsum_ratio  \\\n",
       "354                        0.0                   2                     0.0   \n",
       "1125                       0.0                  31                     0.0   \n",
       "204                        0.0                   1                     0.0   \n",
       "\n",
       "     docq_curly_bracket_ratio  docq_contain_bad_word  docq_bullet_point_ratio  \\\n",
       "354                       0.0                  False                      0.0   \n",
       "1125                      0.0                  False                      0.0   \n",
       "204                       0.0                  False                      0.0   \n",
       "\n",
       "      docq_ellipsis_line_ratio  docq_alphabet_word_ratio  \\\n",
       "354                        0.0                  1.000000   \n",
       "1125                       0.0                  0.648649   \n",
       "204                        0.0                  1.000000   \n",
       "\n",
       "      docq_contain_common_en_words  \n",
       "354                          False  \n",
       "1125                         False  \n",
       "204                           True  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370950a-2a3a-4143-8218-f9b4808099ba",
   "metadata": {},
   "source": [
    "## Step-8:   Text encoding\n",
    "\n",
    "Encode text for the vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a153fa-fd56-401e-86be-4f7617affcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-7: Processing input='output/06_doc_quality_out' --> output='output/07_encoder_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE  += 1\n",
    "# STAGE  = 7 ## DEBUG\n",
    "\n",
    "input_folder = output_folder # previous output folder is the input folder for the current stage\n",
    "output_folder =  os.path.join(MY_CONFIG.OUTPUT_FOLDER, f\"{STAGE:02}_encoder_out\")\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "228df6b2-bc62-494b-9697-03ece98d7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:39:33 INFO - Running locally\n",
      "10:39:33 INFO - text_encoder parameters are : {'content_column_name': 'contents', 'output_embeddings_column_name': 'embeddings', 'model_name': 'sentence-transformers/all-MiniLM-L6-v2'}\n",
      "10:39:33 INFO - data factory data_ is using local data access: input_folder - output/06_doc_quality_out output_folder - output/07_encoder_out\n",
      "10:39:33 INFO - data factory data_ max_files -1, n_sample -1\n",
      "10:39:33 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "10:39:33 INFO - pipeline id pipeline_id\n",
      "10:39:33 INFO - code location None\n",
      "10:39:33 INFO - number of workers 2 worker options {'num_cpus': 1, 'max_restarts': -1}\n",
      "10:39:33 INFO - actor creation delay 0\n",
      "10:39:33 INFO - job details {'job category': 'preprocessing', 'job name': 'text_encoder', 'job type': 'ray', 'job id': 'job_id'}\n",
      "2024-08-30 10:39:35,588\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:39:38 INFO - orchestrator started at 2024-08-30 10:39:38\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:39:38 INFO - Number of files is 2, source profile {'max_file_size': 0.2231884002685547, 'min_file_size': 0.2173166275024414, 'total_file_size': 0.4405050277709961}\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:39:38 INFO - Cluster resources: {'cpus': 16, 'gpus': 1, 'memory': 8.224630738608539, 'object_store': 4.112315367907286}\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:39:38 INFO - Number of workers - 2 with {'num_cpus': 1, 'max_restarts': -1} each\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:39:38 INFO - Completed 0 files (0.0%)  in 6.500879923502604e-06 min. Waiting for completion\n",
      "\u001b[36m(RayTransformFileProcessor pid=1098990)\u001b[0m /home/sujee/apps/anaconda3/envs/data-prep-kit-3-py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[36m(RayTransformFileProcessor pid=1098990)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:40:26 INFO - Completed processing 2 files in 0.7918713609377543 min\n",
      "\u001b[36m(orchestrate pid=1098089)\u001b[0m 10:40:26 INFO - done flushing in 0.0010461807250976562 sec\n",
      "\u001b[36m(RayTransformFileProcessor pid=1098989)\u001b[0m /home/sujee/apps/anaconda3/envs/data-prep-kit-3-py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[36m(RayTransformFileProcessor pid=1098989)\u001b[0m   warnings.warn(\n",
      "10:40:36 INFO - Completed execution in 1.0400522033373514 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:7 completed successfully\n",
      "CPU times: user 510 ms, sys: 285 ms, total: 795 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from text_encoder_transform_ray import TextEncoderRayTransformConfiguration\n",
    "\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "worker_options = {\"num_cpus\" : MY_CONFIG.RAY_NUM_CPUS}\n",
    "params = {\n",
    "    # where to run\n",
    "    \"run_locally\": True,\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    # orchestrator\n",
    "    \"runtime_worker_options\": ParamsUtils.convert_to_ast(worker_options),\n",
    "    \"runtime_num_workers\": MY_CONFIG.RAY_RUNTIME_WORKERS,\n",
    "    # text_encoder\n",
    "    \"text_encoder_model_name\": MY_CONFIG.EMBEDDING_MODEL,\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = RayTransformLauncher(TextEncoderRayTransformConfiguration())\n",
    "# Launch the ray actor(s) to process the input\n",
    "\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"‚ùå Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734852c",
   "metadata": {},
   "source": [
    "### Inspect Generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b1c1d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (1302, 28)\n",
      "Output data dimensions (rows x columns)=  (1302, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.048175987, 0.0011802563, -0.046808466, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Walmart-10K-Reports-Optimized_2023.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>1163</td>\n",
       "      <td>a8118ae6-e6b5-4595-86ed-bf519ec23551</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...</td>\n",
       "      <td>1159974</td>\n",
       "      <td>2024-08-30T10:32:49.798524</td>\n",
       "      <td>321.107279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0038028236, -0.13894859, 0.015160485, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Walmart_2024.pdf</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>1163</td>\n",
       "      <td>00df8499-2863-4ca4-96dc-0c2a2014c3dc</td>\n",
       "      <td>pdf</td>\n",
       "      <td>dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...</td>\n",
       "      <td>1112045</td>\n",
       "      <td>2024-08-30T10:32:40.640835</td>\n",
       "      <td>312.142404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.033763092, 0.031698707, -0.04227217, 0.008...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  num_pages  num_tables  \\\n",
       "916                        Walmart_2024.pdf        100          82   \n",
       "286  Walmart-10K-Reports-Optimized_2023.pdf        100          81   \n",
       "852                        Walmart_2024.pdf        100          82   \n",
       "\n",
       "     num_doc_elements                           document_id  ext  \\\n",
       "916              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "286              1163  a8118ae6-e6b5-4595-86ed-bf519ec23551  pdf   \n",
       "852              1163  00df8499-2863-4ca4-96dc-0c2a2014c3dc  pdf   \n",
       "\n",
       "                                                  hash     size  \\\n",
       "916  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "286  ea5544f26fe0831ec9befbf7aaf68b1b256df6c3ae18b8...  1159974   \n",
       "852  dd3b262828146a536bdc0f04e7c9dfbd7406d043714989...  1112045   \n",
       "\n",
       "                  date_acquired  pdf_convert_time  ...  \\\n",
       "916  2024-08-30T10:32:40.640835        312.142404  ...   \n",
       "286  2024-08-30T10:32:49.798524        321.107279  ...   \n",
       "852  2024-08-30T10:32:40.640835        312.142404  ...   \n",
       "\n",
       "    docq_symbol_to_word_ratio docq_sentence_count docq_lorem_ipsum_ratio  \\\n",
       "916                   0.00000                   3                    0.0   \n",
       "286                   0.00000                  29                    0.0   \n",
       "852                   0.01087                   4                    0.0   \n",
       "\n",
       "     docq_curly_bracket_ratio docq_contain_bad_word  docq_bullet_point_ratio  \\\n",
       "916                       0.0                 False                      0.0   \n",
       "286                       0.0                 False                      0.0   \n",
       "852                       0.0                 False                      0.0   \n",
       "\n",
       "     docq_ellipsis_line_ratio  docq_alphabet_word_ratio  \\\n",
       "916                       0.0                  0.978022   \n",
       "286                       0.0                  0.919414   \n",
       "852                       0.0                  0.978261   \n",
       "\n",
       "     docq_contain_common_en_words  \\\n",
       "916                         False   \n",
       "286                          True   \n",
       "852                         False   \n",
       "\n",
       "                                            embeddings  \n",
       "916  [-0.048175987, 0.0011802563, -0.046808466, -0....  \n",
       "286  [0.0038028236, -0.13894859, 0.015160485, -0.00...  \n",
       "852  [-0.033763092, 0.031698707, -0.04227217, 0.008...  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e12630-be6b-4188-a925-77117155617b",
   "metadata": {},
   "source": [
    "## Step-9: Copy output to final output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16dee3b8-31dc-4168-8adb-f2a0a0b5e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Copied output from 'output/07_encoder_out' --> 'output/output_final'\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_FOLDER_FINAL, ignore_errors=True)\n",
    "shutil.copytree(src=output_folder, dst=MY_CONFIG.OUTPUT_FOLDER_FINAL)\n",
    "\n",
    "print (f\"‚úÖ Copied output from '{output_folder}' --> '{MY_CONFIG.OUTPUT_FOLDER_FINAL}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
